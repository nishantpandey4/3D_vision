              <meta charset="utf-8" emacsmode="-*- markdown -*-">

                            **<big>CMSC848F - Assignment 1 </big>**
							**<big>Rendering Basics with PyTorch3D</big>**
				**Nishant Awdeshkumar Pandey-119247556**
Rendering your first mesh
===============================================================================
The first mesh I rendered was a cow. However, I made some changes in it's 
color making it a different shade of blue as compared to the original .

_Color selected: [0.3, 0.4, 1]_

_Image Size: 512_
![First mesh](../images/cow.jpg)

Practicing with Cameras
===============================================================================
360-degree Renders
-------------------------------------------------------------------------------
To render a 360-degree view of the cow mesh I used **pytorch3d.renderer.look_at_view_transform**.
The distance of the camera from the cow is 5 
units and the elevation is 0 degrees while the 
azimuth is incremented to give a 360-degree view of the cow.

_Color selected: [0.5, 0.3, 1]_

![360-Render](../GIF/my_gif.gif)

Recreating the Dolly zoom
-------------------------------------------------------------------------------
The idea behind it's implementation is to keep changing the FOV of the camera
while moving the camera in such a way that the size of the object remains the same.

\begin{equation}
	2\tan(\frac{FOV}{2})= \frac{W}{D}
\end{equation}

W=Height of the object, D=Distance of the camera from the object,FOV is the field of view of the camera.

However to implement this effect the formula needs to be modified a bit.

\begin{equation}
D_{2}=D_{1}	\frac{\tan(\frac{FOV_1}{2})}{\tan(\frac{FOV_2}{2})}
\end{equation}

I have kept initial D as 50 to match the desired output. 

![Dolly zoom](../GIF/dolly.gif)

Practicing with Meshes
===============================================================================
Constructing a Tetrahedron
-------------------------------------------------------------------------------
![Tetrahedron](../GIF/tetra.gif)

This mesh has 4 vertices and 4 faces. I have selected the vertices such that
all the faces are visibile.

Constructing a Cube
-------------------------------------------------------------------------------
![Cube](../GIF/cube.gif)

_Vertices=8_ , _Triangular Faces=12_

Re-texturing a mesh
===============================================================================

Colors chosen:
_Color1: 0, 1, 1(Blue mixed with green)_

_Color2: 1, 0, 1(Pink)_

![Re-textured](../GIF/cow_tex.gif)

Camera Transformations
===============================================================================
**The First transformed image**

**Explanation in words:** 90 degrees clockwise rotation about z-axis, no translation

_Values - R_relative:[[0, -1, 0], [1, 0, 0], [0, 0, 1]], T_relative:[0, 0, 0]_ 

![First Transformation](../images/first_transform_cow.jpg)

**The Second transformed image**

**Explanation in words:** Translation along +ve z-axis by 2 units, no rotation

_Values - R_relative:[[1, 0, 0], [0, 1, 0], [0, 0, 1]], T_relative:[0, 0, 2]_

![Second Transformation](../images/second_transform_cow.jpg)

**The Third transformed image**

**Explanation in words:** Translation along +ve x-axis and -ve z-axis, no rotation

_Values - R_relative:[[1, 0, 0], [0, 1, 0], [0, 0, 1]], T_relative:[0.5, -0.5, 0]_

![Third Transformation](../images/third_transform_cow.jpg)

**The Fourth transformed image**

**Explanation in words:** Move along +ve x-axis (to the left), Move along +ve z-axis (into the plane)
, 90 degree anticlockwise rotation about the y-axis

_Values - R_relative:[[0, 0, -1], [0, 1, 0], [1, 0, 0]], T_relative:[3, 0, 3]_

![Fourth Transformation](../images/fourth_transform_cow.jpg)

Note: All the values computed where through hit and trial and thus this took a lot of time.

Rendering Generic 3D Representations
===============================================================================
Rendering Point Clouds from RGB-D Images
-------------------------------------------------------------------------------

There are three GIFs below corresponding to the three different point clouds. 
Third one the union of the first two. 

![First Point Cloud](../GIF/plant1.gif) ![Second Point Cloud](../GIF/plant2.gif) ![Third Point Cloud](../GIF/plant3.gif)

There is a difference between the pytorch coordinates and the coordinates of the captured point clouds. Thus had 
correct it using the _up_ argument inside _pytorch3d.renderer.cameras.look_at_view_transform_.

The distance as suggested is 6 for all point clouds. 

Parametric Functions
-------------------------------------------------------------------------------
**Equations Used:**
\begin{equation}
x(\theta,\phi)=(R+r\cos(\theta))\cos(\phi)
\end{equation}
\begin{equation}
y(\theta,\phi)=(R+r\cos(\theta))\sin(\phi)
\end{equation}
\begin{equation}
z(\theta,\phi)=r\sin(\theta);\theta\in[0,2\pi),\phi\in[0,2\pi)
\end{equation}

_num_samples=2000_

![Parametric Function: Torus](../GIF/torus.gif)

Note: The aspect ratio of the torus is 3:2, I have used the same values for R and r respectively.
Just to get the perfect donut shape.

Implicit Surfaces
-------------------------------------------------------------------------------
**Equations Used:**
\begin{equation}
f(x,y,z)=(x^2+y^2-R)^2+z^2-r^2=0
\end{equation}
\begin{equation}
f(x,y,z)=(x^2 + y^2 + z^2 +R^2-r^2)^2-(4)(R^2)(x^2 + y^2)
\end{equation}

Note: To keep R>r, I have used R=3 and r=2 respectively. Also I have used equation (7) to get the torus.

![Implicit Surface: Torus](../GIF/implicit_torus.gif)

**Tradeoffs between rendering as a mesh vs a point cloud:**

1. Rendering as a mesh is more computationally expensive. However, this also depends on the number of vertices in the mesh.

2. Rendering as a mesh is more accurate. The details are more visible as compared to rendering as a point cloud.

3. Rendering as a mesh is more memory intensive as compared to rendering as a point cloud.

4. Rendering as a mesh is more time consuming as compared to rendering as a point cloud. Although I did not feel the difference so much while running on GPU. Also if the point clouds have large number of points it consumes more time.

5. Although each of them have their use cases but rendering as a mesh is visually more appealing.



<link rel="stylesheet" href="https://morgan3d.github.io/markdeep/latest/latex.css?">
<!-- Markdeep: --><style class="fallback">body{visibility:hidden}</style><script src="https://morgan3d.github.io/markdeep/latest/markdeep.min.js?" charset="utf-8"></script>
